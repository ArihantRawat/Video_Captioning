{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1601526540671",
   "display_name": "Python 3.8.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.mapping2 import create_dataset, create_embedding_matrix,  load_all_features\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "r:\\Project\n"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_src = os.path.join(path,'dataset', 'features-small-train')\n",
    "test_feature_src = os.path.join(path,'dataset', 'features-small-test')\n",
    "train_data_src = os.path.join(path, 'dataset', 'MSVD_train-small.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Creating Dataset...: 100%|██████████| 3177/3177 [00:02<00:00, 1391.18it/s]\n"
    }
   ],
   "source": [
    "train_features, padded, target_padded, tokenizer, max_len = create_dataset(\n",
    "    train_feature_src, train_data_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((3177, 20, 4096), (3177, 33), (3177, 33), 33)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "train_features.shape, padded.shape, target_padded.shape, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Loading Features...: 100%|██████████| 20/20 [00:00<00:00, 445.53it/s]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((20, 20, 4096), 20)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "test_feature, test_vid_ids = load_all_features(test_feature_src)\n",
    "test_feature.shape, len(test_vid_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index)\n",
    "embd_vec_size = 100\n",
    "glove_src = os.path.join(path,'dataset','glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Loading Word Embeddings....: 100%|██████████| 400001/400001 [00:24<00:00, 16421.83it/s]\n[ 0.26688    0.39632    0.6169    -0.77451   -0.1039     0.26697\n  0.2788     0.30992    0.0054685 -0.085256   0.73602   -0.098432\n  0.5479    -0.030305   0.33479    0.14094   -0.0070003  0.32569\n  0.22902    0.46557  ]\nEmbed not found for 151 words\n"
    }
   ],
   "source": [
    "embd_matrix = create_embedding_matrix(glove_src, tokenizer.word_index, vocab_size, embd_vec_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((2140, 100), 2139)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "embd_matrix.shape, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_units = 100\n",
    "encoder_input_size = train_features.shape[2]\n",
    "time_steps_enc = train_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "\n",
    "enc_input = Input((None, encoder_input_size), name='enc_input')\n",
    "enc_lstm = LSTM(lstm_units, return_state=True, name='enc_lstm')\n",
    "X = enc_input\n",
    "X = enc_lstm(X)\n",
    "enc_out, enc_h, enc_c = X\n",
    "enc_states = [enc_h, enc_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "\n",
    "dec_input = Input((None,), name='dec_input')\n",
    "dec_embedding = Embedding(vocab_size+1, embd_vec_size, input_length=max_len,\n",
    "                          trainable=False, name='dec_embd', mask_zero=True)\n",
    "dec_lstm = LSTM(lstm_units, return_sequences=True,\n",
    "                return_state=True, name='dec_lstm')\n",
    "dec_dense = Dense(vocab_size+1, activation='softmax')\n",
    "Y = dec_input\n",
    "Y = dec_embedding(Y)\n",
    "Y = dec_lstm(Y, initial_state=enc_states)\n",
    "dec_out, _, _ = Y\n",
    "Y = dec_dense(dec_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "model = Model(inputs=[enc_input, dec_input], outputs=Y)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"functional_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ndec_input (InputLayer)          [(None, None)]       0                                            \n__________________________________________________________________________________________________\nenc_input (InputLayer)          [(None, None, 4096)] 0                                            \n__________________________________________________________________________________________________\ndec_embd (Embedding)            (None, None, 100)    214000      dec_input[0][0]                  \n__________________________________________________________________________________________________\nenc_lstm (LSTM)                 [(None, 100), (None, 1678800     enc_input[0][0]                  \n__________________________________________________________________________________________________\ndec_lstm (LSTM)                 [(None, None, 100),  80400       dec_embd[0][0]                   \n                                                                 enc_lstm[0][1]                   \n                                                                 enc_lstm[0][2]                   \n__________________________________________________________________________________________________\ndense (Dense)                   (None, None, 2140)   216140      dec_lstm[0][0]                   \n==================================================================================================\nTotal params: 2,189,340\nTrainable params: 1,975,340\nNon-trainable params: 214,000\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
    }
   ],
   "source": [
    "plot_model(model, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n25/25 [==============================] - 25s 992ms/step - loss: 1.2493\nEpoch 2/10\n25/25 [==============================] - 49s 2s/step - loss: 1.2317\nEpoch 3/10\n25/25 [==============================] - 43s 2s/step - loss: 1.2150\nEpoch 4/10\n25/25 [==============================] - 48s 2s/step - loss: 1.1993\nEpoch 5/10\n25/25 [==============================] - 41s 2s/step - loss: 1.1843\nEpoch 6/10\n25/25 [==============================] - 36s 1s/step - loss: 1.1698\nEpoch 7/10\n25/25 [==============================] - 38s 2s/step - loss: 1.1557\nEpoch 8/10\n25/25 [==============================] - 35s 1s/step - loss: 1.1417\nEpoch 9/10\n25/25 [==============================] - 34s 1s/step - loss: 1.1276\nEpoch 10/10\n25/25 [==============================] - 32s 1s/step - loss: 1.1127\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x23b21377340>"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "model.fit(x=[train_features,padded], y=target_padded, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((4207, 38), (4207, 38))"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model_inf = Model(enc_input, enc_states)\n",
    "\n",
    "dec_inf_input_h = Input((lstm_units,))\n",
    "dec_inf_input_c = Input((lstm_units,))\n",
    "dec_inf_input_states = [dec_inf_input_h, dec_inf_input_c]\n",
    "\n",
    "dec_inf_out, dec_inf_h, dec_inf_c = dec_lstm(dec_embedding(dec_input),\n",
    "                                             initial_state=dec_inf_input_states)\n",
    "dec_inf_states = [dec_inf_h, dec_inf_c]\n",
    "dec_inf_output = dec_dense(dec_inf_out)\n",
    "\n",
    "decoder_model_inf = Model(inputs=[dec_input] + dec_inf_input_states,\n",
    "                          outputs=[dec_inf_output] + dec_inf_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"functional_11\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nenc_input (InputLayer)       [(None, None, 4096)]      0         \n_________________________________________________________________\nenc_lstm (LSTM)              [(None, 100), (None, 100) 1678800   \n=================================================================\nTotal params: 1,678,800\nTrainable params: 1,678,800\nNon-trainable params: 0\n_________________________________________________________________\n('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
    }
   ],
   "source": [
    "encoder_model_inf.summary()\n",
    "plot_model(encoder_model_inf, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"functional_13\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ndec_input (InputLayer)          [(None, None)]       0                                            \n__________________________________________________________________________________________________\ndec_embd (Embedding)            (None, None, 100)    214000      dec_input[0][0]                  \n__________________________________________________________________________________________________\ninput_5 (InputLayer)            [(None, 100)]        0                                            \n__________________________________________________________________________________________________\ninput_6 (InputLayer)            [(None, 100)]        0                                            \n__________________________________________________________________________________________________\ndec_lstm (LSTM)                 [(None, None, 100),  80400       dec_embd[3][0]                   \n                                                                 input_5[0][0]                    \n                                                                 input_6[0][0]                    \n__________________________________________________________________________________________________\ndense (Dense)                   (None, None, 2140)   216140      dec_lstm[3][0]                   \n==================================================================================================\nTotal params: 510,540\nTrainable params: 296,540\nNon-trainable params: 214,000\n__________________________________________________________________________________________________\n('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
    }
   ],
   "source": [
    "decoder_model_inf.summary()\n",
    "plot_model(decoder_model_inf, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "reverse_word_index = dict([(v,k) for k,v in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(input_seq):\n",
    "\n",
    "    states_val = encoder_model_inf.predict(input_seq)\n",
    "    target_seq = [tokenizer.word_index['\\t']]\n",
    "\n",
    "    predicted_sent = []\n",
    "    stop_condition = False\n",
    "\n",
    "    while not stop_condition:\n",
    "\n",
    "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(\n",
    "            x=[np.array(target_seq)] + states_val)\n",
    "        max_val_index = np.argmax(decoder_out[0, 0])\n",
    "\n",
    "        if reverse_word_index[max_val_index] == '\\n' or max_val_index == 0 or len(predicted_sent) > max_len:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = [max_val_index]\n",
    "        predicted_sent.append(reverse_word_index[max_val_index])\n",
    "        states_val = [decoder_h, decoder_c]\n",
    "\n",
    "    return \" \".join(predicted_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('is is is \\n', ['\\t the rabbit is eating \\n'])"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "index=100\n",
    "generate(np.array([train_features[index]])), tokenizer.sequences_to_texts([padded[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['\\t woman gallops on horse \\n']"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}