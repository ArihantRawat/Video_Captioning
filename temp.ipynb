{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.mapping2 import create_dataset, create_test_dataset, create_embedding_matrix,  load_all_features\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import load_model\n",
    "from IPython.display import Video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "r:\\Project\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_src = os.path.join(path,'dataset', 'features-small-train_X')\n",
    "test_feature_src = os.path.join(path,'dataset', 'features-small-test_X')\n",
    "train_data_src = os.path.join(path, 'dataset', 'MSVD_train-small.csv')\n",
    "test_data_src = os.path.join(path, 'dataset', 'MSVD_test-small.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Creating Train Dataset...: 100%|██████████| 3118/3118 [00:01<00:00, 1561.62it/s]\n"
     ]
    }
   ],
   "source": [
    "train_features, padded, target_padded, tokenizer, max_len, train_vids_ids = create_dataset(\n",
    "    train_feature_src, train_data_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((3118, 20, 2048), (3118, 42), (3118, 42), 42)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "train_features.shape, padded.shape, target_padded.shape, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Creating Test Dataset...: 100%|██████████| 639/639 [00:00<00:00, 2985.97it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((20, 20, 2048), 20, 20)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "test_feature,test_sent, test_vid_ids = create_test_dataset(test_feature_src, test_data_src)\n",
    "test_feature.shape, len(test_vid_ids), len(test_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index)\n",
    "embd_vec_size = 100\n",
    "glove_src = os.path.join(path,'dataset','glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loading Word Embeddings....: 100%|██████████| 400001/400001 [00:20<00:00, 19502.66it/s]\n",
      "[ 0.26688    0.39632    0.6169    -0.77451   -0.1039     0.26697\n",
      "  0.2788     0.30992    0.0054685 -0.085256   0.73602   -0.098432\n",
      "  0.5479    -0.030305   0.33479    0.14094   -0.0070003  0.32569\n",
      "  0.22902    0.46557  ]\n",
      "Embed not found for 197 words\n"
     ]
    }
   ],
   "source": [
    "# embd_matrix = create_embedding_matrix(glove_src, tokenizer.word_index, vocab_size, embd_vec_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embd_matrix.shape, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_units = 100\n",
    "# encoder_input_size = train_features.shape[2]\n",
    "# time_steps_enc = train_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encoder\n",
    "\n",
    "# enc_input = Input((None, encoder_input_size), name='enc_input')\n",
    "# enc_lstm = LSTM(lstm_units, return_state=True, name='enc_lstm')\n",
    "# X = enc_input\n",
    "# X = enc_lstm(X)\n",
    "# enc_out, enc_h, enc_c = X\n",
    "# enc_states = [enc_h, enc_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Decoder\n",
    "\n",
    "# dec_input = Input((None,), name='dec_input')\n",
    "# dec_embedding = Embedding(vocab_size+1, embd_vec_size, input_length=max_len,\n",
    "#                           trainable=False, name='dec_embd', mask_zero=True)\n",
    "# dec_lstm = LSTM(lstm_units, return_sequences=True,\n",
    "#                 return_state=True, name='dec_lstm')\n",
    "# dec_dense = Dense(vocab_size+1, activation='softmax')\n",
    "# Y = dec_input\n",
    "# Y = dec_embedding(Y)\n",
    "# Y = dec_lstm(Y, initial_state=enc_states)\n",
    "# dec_out, _, _ = Y\n",
    "# Y = dec_dense(dec_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model\n",
    "\n",
    "# model = Model(inputs=[enc_input, dec_input], outputs=Y)\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "model = load_model(os.path.join('models','model_v1_X.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ndec_input (InputLayer)          [(None, None)]       0                                            \n__________________________________________________________________________________________________\nenc_input (InputLayer)          [(None, None, 2048)] 0                                            \n__________________________________________________________________________________________________\ndec_embd (Embedding)            (None, None, 50)     113800      dec_input[0][0]                  \n__________________________________________________________________________________________________\nenc_lstm (LSTM)                 [(None, 200), (None, 1799200     enc_input[0][0]                  \n__________________________________________________________________________________________________\ndec_lstm (LSTM)                 [(None, None, 200),  200800      dec_embd[0][0]                   \n                                                                 enc_lstm[0][1]                   \n                                                                 enc_lstm[0][2]                   \n__________________________________________________________________________________________________\ndense (Dense)                   (None, None, 2276)   457476      dec_lstm[0][0]                   \n==================================================================================================\nTotal params: 2,571,276\nTrainable params: 2,457,476\nNon-trainable params: 113,800\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_model(model, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch_size = 1\n",
    "# epochs = 1\n",
    "\n",
    "# model.fit(x=[train_features,padded], y=target_padded, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features.shape,  target_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# encoder_model_inf = Model(enc_input, enc_states)\n",
    "\n",
    "# dec_inf_input_h = Input((lstm_units,))\n",
    "# dec_inf_input_c = Input((lstm_units,))\n",
    "# dec_inf_input_states = [dec_inf_input_h, dec_inf_input_c]\n",
    "\n",
    "# dec_inf_out, dec_inf_h, dec_inf_c = dec_lstm(dec_embedding(dec_input),\n",
    "#                                              initial_state=dec_inf_input_states)\n",
    "# dec_inf_states = [dec_inf_h, dec_inf_c]\n",
    "# dec_inf_output = dec_dense(dec_inf_out)\n",
    "\n",
    "# decoder_model_inf = Model(inputs=[dec_input] + dec_inf_input_states,\n",
    "#                           outputs=[dec_inf_output] + dec_inf_states)\n",
    "\n",
    "encoder_model_inf = load_model(os.path.join('models','encoder_model_inf_v1_X.h5'))\n",
    "decoder_model_inf = load_model(os.path.join('models','decoder_model_inf_v1_X.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nenc_input (InputLayer)       [(None, None, 2048)]      0         \n_________________________________________________________________\nenc_lstm (LSTM)              [(None, 200), (None, 200) 1799200   \n=================================================================\nTotal params: 1,799,200\nTrainable params: 1,799,200\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model_inf.summary()\n",
    "# plot_model(encoder_model_inf, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_2\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ndec_input (InputLayer)          [(None, None)]       0                                            \n__________________________________________________________________________________________________\ndec_embd (Embedding)            (None, None, 50)     113800      dec_input[0][0]                  \n__________________________________________________________________________________________________\ninput_1 (InputLayer)            [(None, 200)]        0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            [(None, 200)]        0                                            \n__________________________________________________________________________________________________\ndec_lstm (LSTM)                 [(None, None, 200),  200800      dec_embd[0][0]                   \n                                                                 input_1[0][0]                    \n                                                                 input_2[0][0]                    \n__________________________________________________________________________________________________\ndense (Dense)                   (None, None, 2276)   457476      dec_lstm[0][0]                   \n==================================================================================================\nTotal params: 772,076\nTrainable params: 658,276\nNon-trainable params: 113,800\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model_inf.summary()\n",
    "# plot_model(decoder_model_inf, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2275"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "reverse_word_index = dict([(v,k) for k,v in word_index.items()])\n",
    "len(reverse_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(input_seq):\n",
    "\n",
    "    states_val = encoder_model_inf.predict(input_seq)\n",
    "    target_seq = [tokenizer.word_index['\\t']]\n",
    "\n",
    "    predicted_sent = []\n",
    "    stop_condition = False\n",
    "\n",
    "    while not stop_condition:\n",
    "\n",
    "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(\n",
    "            x=[np.array(target_seq)] + states_val)\n",
    "        max_val_index = np.argmax(decoder_out[0, 0])\n",
    "\n",
    "        if reverse_word_index[max_val_index] == '\\n' or max_val_index == 0 or len(predicted_sent) > max_len:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = [max_val_index]\n",
    "        predicted_sent.append(reverse_word_index[max_val_index])\n",
    "        states_val = [decoder_h, decoder_c]\n",
    "\n",
    "    return \" \".join(predicted_sent).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original:  man is rolling bowling ball into the two remaining bowling pins\n",
      "Predicted:  man is playing bowling game hits many bottles\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'lc9bA-hvqHU_1_6.avi'"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "index=3000\n",
    "print('Original: ',tokenizer.sequences_to_texts([padded[index]])[0].strip())\n",
    "print('Predicted: ',generate(np.array([train_features[index]])))\n",
    "train_vids_ids[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original:  person falls off while riding dirt bike\n",
      "Predicted:  man is riding on over horse\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'nhm_APPwhWk_6_12.avi'"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "index=4\n",
    "print('Original: ',\" \".join(test_sent[index]).strip())\n",
    "print('Predicted: ',generate(np.array([test_feature[index]])))\n",
    "test_vid_ids[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}